{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Using CountVectorizer from scikit-learn- http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to perfom semantic data analysis of movie reviews provided by imdb. The sentiments are classified as Positive(1) or Negative(0) describing whether the review is positive or negative. The dataset we are using is obtained from kaggle(https://www.kaggle.com/c/word2vec-nlp-tutorial/download/labeledTrainData.tsv.zip). The dataset contains 3 columns and 25000 rows. We will be using 20000 entries for training our model and another 5000 for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import the dependencies that we will be using later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. numpy- for handling multidimensional arrays and scientific calculations\n",
    "2. pandas- for data manipulation and handling in a structured manner\n",
    "3. train_test_split- separating training and testing data to check performance of model for new inputs\n",
    "4. BeautifulSoup- to remove all the html markups in review text\n",
    "5. re- regular expression to remove everything except alphabets\n",
    "6. nltk- natural language toolkit used in removing stopwords\n",
    "7. CountVectorizer- to extract features from string data and convert them to vectors\n",
    "8. svm- support vector machine to train the model and predict the output\n",
    "9. shuffle- to shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to read the data in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/kr_subham/Desktop/GitHub/TextClassification/reviews_imdb.tsv', delimiter='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains 3 columns- id, sentiment and review. Since id is of no use to us, we will drop that column from our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  With all this stuff going down at the moment w...\n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2          0  The film starts with a manager (Nicholas Bell)...\n",
       "3          0  It must be assumed that those who praised this...\n",
       "4          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('id', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is better to shuffle the data. It will help us generalize the model by removing any patterns in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a bad word to say about this film really. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>0</td>\n",
       "      <td>Highly implausible, unbelievable, and incohere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1</td>\n",
       "      <td>Being a fan of the first Lion King, I was defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20339</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm sure this is a show no one is that familia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>1</td>\n",
       "      <td>Minor Spoilers&lt;br /&gt;&lt;br /&gt;Alison Parker (Crist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                             review\n",
       "947            1  Not a bad word to say about this film really. ...\n",
       "5258           0  Highly implausible, unbelievable, and incohere...\n",
       "624            1  Being a fan of the first Lion King, I was defi...\n",
       "20339          1  I'm sure this is a show no one is that familia...\n",
       "3957           1  Minor Spoilers<br /><br />Alison Parker (Crist..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains 25000 rows and 2 columns, as seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third step is to preprocess the data. We will be creating several functions along the way which will help in processing the data to be fed in the Support Vector Machine algorithm. This preprocessing will also help us in imporving the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Most people, especially young people, may not understand this film. It looks like a story of loss, when it is actually a story about being alone. Some people may never feel loneliness at this level.<br /><br />Cheadles character Johnson reflected the total opposite of Sandlers character Fineman. Where Johnson felt trapped by his blessings, Fineman was trying to forget his life in the same perspective. Jada is a wonderful additive to the cast and Sandler pulls tears. Cheadle had the comic role and was a great supporter for Sandler.<br /><br />I see Oscars somewhere here. A very fine film. If you have ever lost and felt alone, this film will assure you that you're not alone.<br /><br />Jerry\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to remove all the html tags from the review. For this we are using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Possibly not, but it is awful. Even the fantastic cast cant save it. OK, I admit it started off quite funny but it seemed to plummet downhill as soon as they jumped those girls in the Generals house. Bill Murray turned from being a quick witted, humorous guy into an arsehole who was shouting things at people in the street that just weren't funny, its like he was trying too hard to be funny. His character stole a weapon (an RV? come on...) and ends up being a national hero after invading another country and killing god knows how many soldiers, for a laugh. One good point is that this film shows the inadequacy and incompetence of the US Army and shows how arrogant and imbecilic they really are, albeit unintentionally. I actually felt disgusted that this kind of propaganda crap could really be released.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_html = []\n",
    "def remove_html(raw_review):\n",
    "    flag = BeautifulSoup(raw_review, 'html5lib')\n",
    "    return flag.get_text()\n",
    "\n",
    "for i in data['review']:\n",
    "    no_html.append(remove_html(i))\n",
    "    \n",
    "no_html[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above segment, we created an empty list which will hold the reviews after removing the markups. remove_html function takes any review as an input and returns the review without markup. The for-loop iterates through all the reviews in our data. The list no_html is a list of list containing all the reviews without markup and each review from the data is a separate list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to remove punctuations, numbers etc because they are not much useful. We are using re for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Possibly not  but it is awful  Even the fantastic cast cant save it  OK  I admit it started off quite funny but it seemed to plummet downhill as soon as they jumped those girls in the Generals house  Bill Murray turned from being a quick witted  humorous guy into an arsehole who was shouting things at people in the street that just weren t funny  its like he was trying too hard to be funny  His character stole a weapon  an RV  come on     and ends up being a national hero after invading another country and killing god knows how many soldiers  for a laugh  One good point is that this film shows the inadequacy and incompetence of the US Army and shows how arrogant and imbecilic they really are  albeit unintentionally  I actually felt disgusted that this kind of propaganda crap could really be released '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_only = []\n",
    "def keep_text(raw_review):\n",
    "    flag = re.sub('[^a-zA-Z]', ' ', raw_review)\n",
    "    return flag\n",
    "\n",
    "for i in no_html:\n",
    "    text_only.append(keep_text(i))\n",
    "    \n",
    "text_only[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_only is a list that contains reviews without any punctuations or numbers. These are replaced by a blank space, as seen above. The elements in text_only are separated by commas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert all the text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'possibly not  but it is awful  even the fantastic cast cant save it  ok  i admit it started off quite funny but it seemed to plummet downhill as soon as they jumped those girls in the generals house  bill murray turned from being a quick witted  humorous guy into an arsehole who was shouting things at people in the street that just weren t funny  its like he was trying too hard to be funny  his character stole a weapon  an rv  come on     and ends up being a national hero after invading another country and killing god knows how many soldiers  for a laugh  one good point is that this film shows the inadequacy and incompetence of the us army and shows how arrogant and imbecilic they really are  albeit unintentionally  i actually felt disgusted that this kind of propaganda crap could really be released '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_text = []\n",
    "def lowercase(raw_review):\n",
    "    return raw_review.lower()\n",
    "\n",
    "for i in text_only:\n",
    "    lower_text.append(lowercase(i))\n",
    "    \n",
    "lower_text[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to tokenize the sentences into a list of individual words and then remove stopwords from that list.\n",
    "We will use the split function to create word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['possibly', 'not', 'but', 'it', 'is']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_words = []\n",
    "def tokens(raw_review):\n",
    "    return raw_review.split()\n",
    "\n",
    "for i in lower_text:\n",
    "    tokenize_words.append(tokens(i))\n",
    "    \n",
    "tokenize_words[19][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize_words is a list of lists containing tokens(including stopwords) for each sentence in the review(lower_text). The first 5 tokens of the 19th entry is shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use nltk to remove stopwords. nltk contains a large vocabulary of predefined stopwords. We will compare each token in our list to the words in nltk corpus and remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['possibly', 'awful', 'even', 'fantastic', 'cast']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stopwords = []\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "def remove_stopwords(raw_review):\n",
    "    raw_review = [w for w in raw_review if not w in stopwords ]\n",
    "    return raw_review\n",
    "\n",
    "for i in tokenize_words:\n",
    "    no_stopwords.append(remove_stopwords(i))\n",
    "    \n",
    "no_stopwords[19][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finishes our preprocessing. we will now join the remaining words from each review to form sentences and then save those sentences along with their sentiment in a new clean dataframe(This step is not mandatory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad word say film really initially impressed g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>highly implausible unbelievable incoherent spa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fan first lion king definitely looking forward...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sure show one familiar might think good almost...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minor spoilersalison parker cristina raines su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  bad word say film really initially impressed g...          1\n",
       "1  highly implausible unbelievable incoherent spa...          0\n",
       "2  fan first lion king definitely looking forward...          1\n",
       "3  sure show one familiar might think good almost...          1\n",
       "4  minor spoilersalison parker cristina raines su...          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for i in no_stopwords:\n",
    "    sentences.append(' '.join(word for word in i))\n",
    "    \n",
    "dict_review = {'review':[i for i in sentences], 'sentiment':[j for j in data['sentiment']]}\n",
    "data_clean = pd.DataFrame(dict_review, columns=['review', 'sentiment'])\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_clean is a new DataFrame that contains clean reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the cleaned data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_clean, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 8000)\n",
      "(5000, 8000)\n"
     ]
    }
   ],
   "source": [
    "countVect = CountVectorizer(max_features=8000)\n",
    "x_train_counts = countVect.fit_transform(train['review'])\n",
    "x_test_counts = countVect.fit_transform(test['review'])\n",
    "print(x_train_counts.shape)\n",
    "print(x_test_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows we have 20000 entries(vectors) for train data and 5000 for test data with 8000 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will use support vector machine to fit our model and predict the output. We will display accuracy of test data to see how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm = svm.SVC(kernel='rbf', C=10.0)\n",
    "clf_svm.fit(x_train_counts, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using SVM:  0.6208\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = clf_svm.score(x_test_counts, test['sentiment'])\n",
    "print('Test accuracy using SVM: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on test data using support vector machines is 0.6208(or 62.08%). This shows the model performs fairly well on new data as well. The performance can be improved by changing several performance and experimenting new techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
